---
layout: archive
---

I am a research assistant in the department of Computer Science at 
<a href="https://www.purdue.edu">Purdue University</a>
, working on computer security and system security in 
<a href="https://pursec.cs.purdue.edu">PurSec Lab.</a>
I received my M.S and B.S from Computer Engineering department at 
<a href="https://www.metu.edu.tr">METU</a>
 in 2020 and 2017, respectively.
<br>
Previously, I worked at 
<a href="https://www.comodo.com">Comodo</a>
, evaluating the malware classification. I also interned at 
<a href="https://www.sap.com/index.html">SAP</a>
 and 
 <a href="https://deepai.org/publication/proceedings-of-enterface-2015-workshop-on-intelligent-interfaces">eNTERFACE'15</a>
 when I was undergrad.
<br>
I am actively working on android security and privacy, malware analysis, practical deep learning applications in security, safety and security of automated systems.
<hr>

<table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody><tr style="padding:0px">
    <td style="padding:0px">
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody><tr style="padding:0px">
          <td style="padding:2.5%;width:20%;max-width:20%">
            <a href="https://giddyyupp.github.io/" target="_blank">
              <img style="width:100%;max-width:100%;border-radius: 10%;" alt="profile photo" src="images/profile.jpg">
            </a>
          </td>
          <td style="padding:2.5%;width:60%;vertical-align:middle">
            <h1>
              Nermin Samet
            </h1>
            <p>
            I am a postdoctoral researcher at <a href="https://www.ecoledesponts.fr/" target="_blank"> ENPC ParisTech</a>, <a href="https://imagine-lab.enpc.fr/" target="_blank"> IMAGINE Research Group</a> working with <a href="https://vincentlepetit.github.io/" target="_blank"> Prof. Vincent Lepetit</a>.
I obtained my Ph.D. degree in 2021 from the <a href="http://ceng.metu.edu.tr/" target="_blank"> Department of Computer Engineering</a> at <a href="http://www.metu.edu.tr/" target="_blank">Middle East Technical University</a> under supervision of <a href="http://user.ceng.metu.edu.tr/~emre/" target="_blank">Dr. Emre Akbas</a>. My primary research interest is computer vision focusing on (video) object detection.
            </p>
            <p style="text-align:center">
              </p><div class="contact-buttons">
                <a href="mailto:nermin.samet@metu.edu.tr" target="_blank"><i class="far fa-envelope fa-2x"></i></a>
                <a href="https://github.com/nerminsamet" target="_blank"><i class="fab fa-github fa-2x"></i></a>
                <a href="https://scholar.google.com/citations?user=kEVeHU0AAAAJ" target="_blank"><i class="ai ai-google-scholar fa-2x"></i></a>
                <a href="https://www.linkedin.com/in/nermin-samet-a70007156" target="_blank"><i class="fab fa-linkedin-in fa-2x"></i></a>
                <a href="https://twitter.com/nemka_" target="_blank"><i class="fab fa-twitter fa-2x"></i></a>
                <a href="https://www.youtube.com/user/nemka911/videos" target="_blank"><i class="fab fa-youtube fa-2x"></i></a>
                <!-- <a href="" target="_blank"><i class="fab fa-flickr fa-2x"></i></a> -->
              </div>
            <p></p>
          </td>
        </tr>
      </tbody></table>

      <hr>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody><tr>
          <td style="padding:2.5% 2.5% 0% 2.5%;width:100%;vertical-align:middle">
            <h2><b>News</b></h2>
          </td>
        </tr>
      </tbody></table>

      <div class="timeline">
        <div class="timeline-news">

          
          
          
          <div class="timeline-item">
            <div class="timeline-date">
              <div class="timeline-dot" style="background-color: #b5e7a0;"></div>
              <span style="background-color: #b5e7a0;">Aug 2022</span>
              <p class="timeline-title">Our extended work on <a href="https://arxiv.org/abs/2104.06773" target="_blank">HoughNet</a> is accepted to the IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI).</p>
            </div>
          </div>
          
          
          
          
          
          <div class="timeline-item">
            <div class="timeline-date">
              <div class="timeline-dot" style="background-color: #6495ED;"></div>
              <span style="background-color: #6495ED;">Nov 2021</span>
              <p class="timeline-title">I am among the <a href="https://www.bmvc2021-virtualconference.com/people/reviewers/" target="_blank"> outstanding BMVC2021 reviewers</a>!</p>
            </div>
          </div>
          
          
          
          
          
          <div class="timeline-item">
            <div class="timeline-date">
              <div class="timeline-dot" style="background-color: #6495ED;"></div>
              <span style="background-color: #6495ED;">Nov 2021</span>
              <p class="timeline-title">I started my Postdoc at <a href="https://www.ecoledesponts.fr/" target="_blank">École des Ponts (ENPC) ParisTech</a>, <a href="https://imagine-lab.enpc.fr/" target="_blank">IMAGINE Research Group</a>.</p>
            </div>
          </div>
          
          
          
          
          
          <div class="timeline-item">
            <div class="timeline-date">
              <div class="timeline-dot" style="background-color: #6495ED;"></div>
              <span style="background-color: #6495ED;">Oct 2021</span>
              <p class="timeline-title">I will be co-organizing the <a href="https://sites.google.com/view/wicv/" target="_blank">Women in Computer Vision Workshop</a> at <a href="https://cvpr2022.thecvf.com/" target="_blank">CVPR 2022</a>.</p>
            </div>
          </div>
          
          
          
          
          
          <div class="timeline-item">
            <div class="timeline-date">
              <div class="timeline-dot" style="background-color: #6495ED;"></div>
              <span style="background-color: #6495ED;">Sep 2021</span>
              <p class="timeline-title">I successfully defended my Ph.D thesis. <a href="https://drive.google.com/file/d/14I1a4VFekvDoVgnSG7USU6NlL-Prr_0Z/view?usp=sharing" target="_blank">Here is my acedemic family tree</a> (<a href="https://www.genealogy.math.ndsu.nodak.edu/" target="_blank">source</a>).</p>
            </div>
          </div>
          
          
          
          
          
          <div class="timeline-item">
            <div class="timeline-date">
              <div class="timeline-dot" style="background-color: #6495ED;"></div>
              <span style="background-color: #6495ED;">Sep 2021</span>
              <p class="timeline-title">HPRNet is accepted to Image and Vision Computing: <a href="https://www.sciencedirect.com/science/article/pii/S0262885621001906?via%3Dihub" target="_blank">publisher's page</a> </p>
            </div>
          </div>
          
          
          
          
          
          <div class="timeline-item">
            <div class="timeline-date">
              <div class="timeline-dot" style="background-color: #6495ED;"></div>
              <span style="background-color: #6495ED;">Jun 2021</span>
              <p class="timeline-title">Our paper entitled “HPRNet: Hierarchical Point Regression for Whole-Body Human Pose Estimation” is now available on <a href="https://arxiv.org/abs/2106.04269" target="_blank">arXiv</a>.</p>
            </div>
          </div>
          
          
          
          
          
          <div class="timeline-item">
            <div class="timeline-date">
              <div class="timeline-dot" style="background-color: #6495ED;"></div>
              <span style="background-color: #6495ED;">May 2021</span>
              <p class="timeline-title">Our paper “Adversarial Segmentation Loss for Sketch Colorization” is accepted to the International Conference on Image Processing (ICIP).</p>
            </div>
          </div>
          
          
          
          
          
          <div class="timeline-item">
            <div class="timeline-date">
              <div class="timeline-dot" style="background-color: #6495ED;"></div>
              <span style="background-color: #6495ED;">Apr 2021</span>
              <p class="timeline-title">Our extended work on HoughNet, “HoughNet: Integrating near and long-range evidence for visual detection” is now available on <a href="https://arxiv.org/abs/2104.06773" target="_blank">arXiv</a>.</p>
            </div>
          </div>
          
          
          
          
          
          <div class="timeline-item">
            <div class="timeline-date">
              <div class="timeline-dot" style="background-color: #6495ED;"></div>
              <span style="background-color: #6495ED;">Feb 2021</span>
              <p class="timeline-title">Our paper entitled “Adversarial Segmentation Loss for Sketch Colorization” is now available on <a href="https://arxiv.org/abs/2102.06192" target="_blank">arXiv</a>.</p>
            </div>
          </div>
          
          
          
          
          
          <div class="timeline-item">
            <div class="timeline-date">
              <div class="timeline-dot" style="background-color: #ff5733;"></div>
              <span style="background-color: #ff5733;">Oct 2020</span>
              <p class="timeline-title">I will be co-organizing the <a href="https://sites.google.com/view/wicvcvpr2021/home" target="_blank">Women in Computer Vision Workshop</a> at <a href="http://cvpr2021.thecvf.com/" target="_blank">CVPR 2021</a>.</p>
            </div>
          </div>
          
          
          
          
          
          <div class="timeline-item">
            <div class="timeline-date">
              <div class="timeline-dot" style="background-color: #ff5733;"></div>
              <span style="background-color: #ff5733;">Sep 2020</span>
              <p class="timeline-title">Our work <a href="https://arxiv.org/abs/2002.05638" target="_blank">GANILLA</a> has been featured in “<a href="https://blog.deeplearning.ai/blog/the-batch-gan-special-issue-ian-goodfellow-for-real-detecting-fakes-including-minorities-synthesizing-training-data-applying-virtual-make-up" target="_blank">The Batch</a>”, a new weekly newsletter from deeplearning.ai. </p>
            </div>
          </div>
          
          
          
          
          
          <div class="timeline-item">
            <div class="timeline-date">
              <div class="timeline-dot" style="background-color: #ff5733;"></div>
              <span style="background-color: #ff5733;">Aug 2020</span>
              <p class="timeline-title">Our paper entitled “<a href="https://arxiv.org/abs/2008.01167" target="_blank">Reducing Label Noise in Anchor-Free Object Detection</a>” is accepted to the British Machine Vision Conference (BMVC).</p>
            </div>
          </div>
          
          
          
          
          
          <div class="timeline-item">
            <div class="timeline-date">
              <div class="timeline-dot" style="background-color: #ff5733;"></div>
              <span style="background-color: #ff5733;">Jun 2020</span>
              <p class="timeline-title">Our paper entitled “<a href="https://arxiv.org/abs/2007.02355" target="_blank">HoughNet: Integrating near and long-range evidence for bottom-up object detection</a>” is accepted to the European Conference on Computer Vision (ECCV).</p>
            </div>
          </div>
          
          
          
          
          
          <div class="timeline-item">
            <div class="timeline-date">
              <div class="timeline-dot" style="background-color: #ff5733;"></div>
              <span style="background-color: #ff5733;">Jan 2020</span>
              <p class="timeline-title">Our paper entitled “<a href="https://arxiv.org/abs/2002.05638" target="_blank">GANILLA: Generative adversarial networks for image to illustration translation</a>” is accepted to Image and Vision Computing.</p>
            </div>
          </div>
          
          
          

        </div>
      </div>

      <hr>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody><tr>
          <td style="padding:2.5% 2.5% 0% 2.5%;width:100%;vertical-align:middle">
            <h2><b>Research</b></h2>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

        
        
        
        <tbody><tr>
          <td style="padding:2.5%;width:75%;vertical-align:middle">
            <h3>HoughNet: Integrating near and long-range evidence for visual detection</h3>
            <br>
            <strong>Nermin Samet</strong>, Samet Hicsonmez, Emre Akbas

            <br>
            <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</em> 2022<br>
            <div class="research-buttons">
              
              <a href="https://arxiv.org/abs/2104.06773" target="_blank"><button type="button" class="research-button"><i class="ai ai-arxiv fa-lg"></i><span>arXiv</span></button></a>
              
              
              <a href="https://ieeexplore.ieee.org/document/9864076" target="_blank"><button type="button" class="research-button"><i class="far fa-file-pdf fa-lg"></i><span>Paper</span></button></a>
              
              
              <a href="https://github.com/nerminsamet/houghnet" target="_blank"><button type="button" class="research-button"><i class="fab fa-github fa-lg"></i><span>Code</span></button></a>
              
              
              
              
              
              <a href="javascript:toggleBib('bib/extendedhoughnet.bib')"><button type="button" class="research-button"><span>BibTeX</span></button></a>
              
            </div>
            

            
            <pre id="bib/extendedhoughnet.bib" style="display: none;">@misc{HoughNet2021,
    title={HoughNet: Integrating near and long-range evidence for visual detection}, 
    author={Nermin Samet and Samet Hicsonmez and Emre Akbas},
    year={2021}, 
}
</pre>
            
          </td>
        </tr>
        
        
        
        
        
        <tr>
          <td style="padding:2.5%;width:75%;vertical-align:middle">
            <h3>HPRNet: Hierarchical Point Regression for Whole-Body Human Pose Estimation</h3>
            <br>
            <strong>Nermin Samet</strong>, Emre Akbas

            <br>
            <em>Image and Vision Computing (IMAVIS)</em> 2021<br>
            <div class="research-buttons">
              
              <a href="https://arxiv.org/abs/2106.04269" target="_blank"><button type="button" class="research-button"><i class="ai ai-arxiv fa-lg"></i><span>arXiv</span></button></a>
              
              
              <a href="https://www.sciencedirect.com/science/article/pii/S0262885621001906?via%3Dihub" target="_blank"><button type="button" class="research-button"><i class="far fa-file-pdf fa-lg"></i><span>Paper</span></button></a>
              
              
              <a href="https://github.com/nerminsamet/HPRNet" target="_blank"><button type="button" class="research-button"><i class="fab fa-github fa-lg"></i><span>Code</span></button></a>
              
              
              
              
              
              <a href="javascript:toggleBib('bib/hprnet.bib')"><button type="button" class="research-button"><span>BibTeX</span></button></a>
              
            </div>
            

            
            <pre id="bib/hprnet.bib" style="display: none;">@article{samet2021_hprnet,
title = {HPRNet: Hierarchical point regression for whole-body human pose estimation},
journal = {Image and Vision Computing},
pages = {104285},
year = {2021},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2021.104285},
author = {Nermin Samet and Emre Akbas},
}
</pre>
            
          </td>
        </tr>
        
        
        
        
        
        <tr>
          <td style="padding:2.5%;width:75%;vertical-align:middle">
            <h3>Adversarial Segmentation Loss for Sketch Colorization</h3>
            <br>
            Samet Hicsonmez, <strong>Nermin Samet</strong>, Emre Akbas, Pinar Duygulu

            <br>
            <em>International Conference on Image Processing (ICIP)</em> 2021<br>
            <div class="research-buttons">
              
              <a href="https://arxiv.org/abs/2102.06192" target="_blank"><button type="button" class="research-button"><i class="ai ai-arxiv fa-lg"></i><span>arXiv</span></button></a>
              
              
              <a href="https://ieeexplore.ieee.org/document/9506637" target="_blank"><button type="button" class="research-button"><i class="far fa-file-pdf fa-lg"></i><span>Paper</span></button></a>
              
              
              <a href="https://github.com/giddyyupp/AdvSegLoss" target="_blank"><button type="button" class="research-button"><i class="fab fa-github fa-lg"></i><span>Code</span></button></a>
              
              
              
              
              
              <a href="javascript:toggleBib('bib/advsegloss.bib')"><button type="button" class="research-button"><span>BibTeX</span></button></a>
              
            </div>
            

            
            <pre id="bib/advsegloss.bib" style="display: none;">@INPROCEEDINGS{hicsonmez2021_advseg,
author={Hicsonmez, Samet and Samet, Nermin and Akbas, Emre and Duygulu, Pinar},
booktitle={2021 IEEE International Conference on Image Processing (ICIP)}, 
title={Adversarial Segmentation Loss For Sketch Colorization}, 
year={2021},
pages={2403-2407},
doi={10.1109/ICIP42928.2021.9506637}
}
</pre>
            
          </td>
        </tr>
        
        
        
        
        
        <tr>
          <td style="padding:2.5%;width:75%;vertical-align:middle">
            <h3>Reducing Label Noise in Anchor-Free Object Detection</h3>
            <br>
            <strong>Nermin Samet</strong>, Samet Hicsonmez, Emre Akbas

            <br>
            <em>British Machine Vision Conference (BMVC)</em> 2020<br>
            <div class="research-buttons">
              
              <a href="https://arxiv.org/abs/2008.01167" target="_blank"><button type="button" class="research-button"><i class="ai ai-arxiv fa-lg"></i><span>arXiv</span></button></a>
              
              
              
              <a href="https://github.com/nerminsamet/ppdet" target="_blank"><button type="button" class="research-button"><i class="fab fa-github fa-lg"></i><span>Code</span></button></a>
              
              
              
              
              
              <a href="javascript:toggleBib('bib/ppdet.bib')"><button type="button" class="research-button"><span>BibTeX</span></button></a>
              
            </div>
            

            
            <pre id="bib/ppdet.bib" style="display: none;">@inproceedings{PPDet,
author = {Nermin Samet and Samet Hicsonmez and Emre Akbas},
title = {Reducing {L}abel {N}oise in {A}nchor-{F}ree {O}bject {D}etection},
booktitle = {British Machine Vision Conference (BMVC)},
year = {2020},
}
</pre>
            
          </td>
        </tr>
        
        
        
        
        
        <tr>
          <td style="padding:2.5%;width:75%;vertical-align:middle">
            <h3>HoughNet: Integrating near and long-range evidence for bottom-up object detection</h3>
            <br>
            <strong>Nermin Samet</strong>, Samet Hicsonmez, Emre Akbas

            <br>
            <em>European Conference on Computer Vision (ECCV)</em> 2020<br>
            <div class="research-buttons">
              
              <a href="https://arxiv.org/abs/2007.02355" target="_blank"><button type="button" class="research-button"><i class="ai ai-arxiv fa-lg"></i><span>arXiv</span></button></a>
              
              
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-58595-2_25" target="_blank"><button type="button" class="research-button"><i class="far fa-file-pdf fa-lg"></i><span>Paper</span></button></a>
              
              
              <a href="https://github.com/nerminsamet/houghnet" target="_blank"><button type="button" class="research-button"><i class="fab fa-github fa-lg"></i><span>Code</span></button></a>
              
              
              <a href="https://www.youtube.com/watch?v=u8O3pk-v5Us" target="_blank"><button type="button" class="research-button"><i class="fas fa-video fa-lg"></i><span>Video</span></button></a>
              
              
              
              
              <a href="javascript:toggleBib('bib/houghnet.bib')"><button type="button" class="research-button"><span>BibTeX</span></button></a>
              
            </div>
            

            
            <pre id="bib/houghnet.bib" style="display: none;">@inproceedings{samet2020houghnet,
title={HoughNet: Integrating near and long-range evidence for bottom-up object detection},
author={Samet, Nermin and Hicsonmez, Samet and Akbas, Emre},
booktitle={European Conference on Computer Vision},
pages={406--423},
year={2020},
organization={Springer}
}
</pre>
            
          </td>
        </tr>
        
        
        
        
        
        <tr>
          <td style="padding:2.5%;width:75%;vertical-align:middle">
            <h3>GANILLA: Generative adversarial networks for image to illustration translation</h3>
            <br>
            Samet Hicsonmez, <strong>Nermin Samet</strong>, Emre Akbas, Pinar Duygulu

            <br>
            <em>Image and Vision Computing (IMAVIS)</em> 2020<br>
            <div class="research-buttons">
              
              <a href="https://arxiv.org/abs/2002.05638" target="_blank"><button type="button" class="research-button"><i class="ai ai-arxiv fa-lg"></i><span>arXiv</span></button></a>
              
              
              <a href="https://www.sciencedirect.com/science/article/pii/S0262885620300184" target="_blank"><button type="button" class="research-button"><i class="far fa-file-pdf fa-lg"></i><span>Paper</span></button></a>
              
              
              <a href="https://github.com/giddyyupp/ganilla" target="_blank"><button type="button" class="research-button"><i class="fab fa-github fa-lg"></i><span>Code</span></button></a>
              
              
              <a href="https://www.youtube.com/watch?v=-IbNmc2mTz4" target="_blank"><button type="button" class="research-button"><i class="fas fa-video fa-lg"></i><span>Video</span></button></a>
              
              
              
              
              <a href="javascript:toggleBib('bib/ganilla.bib')"><button type="button" class="research-button"><span>BibTeX</span></button></a>
              
            </div>
            

            
            <pre id="bib/ganilla.bib" style="display: none;">@article{hicsonmez2020ganilla,
title={GANILLA: Generative adversarial networks for image to illustration translation},
author={Hicsonmez, Samet and Samet, Nermin and Akbas, Emre and Duygulu, Pinar},
journal={Image and Vision Computing},
volume={95},
pages={103886},
year={2020},
publisher={Elsevier}
}
</pre>
            
          </td>
        </tr>
        
        
        
        
        
        <tr>
          <td style="padding:2.5%;width:75%;vertical-align:middle">
            <h3>Could We Create A Training Set For Image Captioning Using Automatic Translation?</h3>
            <br>
            <strong>Nermin Samet</strong>, Samet Hicsonmez, Pinar Duygulu, Emre Akbas

            <br>
            <em>Signal Processing and Communications Applications Conference (SIU)</em> 2017<br>
            <div class="research-buttons">
              
              
              <a href="https://ieeexplore.ieee.org/abstract/document/7960638" target="_blank"><button type="button" class="research-button"><i class="far fa-file-pdf fa-lg"></i><span>Paper</span></button></a>
              
              
              <a href="https://github.com/giddyyupp/turkish-image-captioning" target="_blank"><button type="button" class="research-button"><i class="fab fa-github fa-lg"></i><span>Code</span></button></a>
              
              
              
              
              
              <a href="javascript:toggleBib('bib/turkishcapt.bib')"><button type="button" class="research-button"><span>BibTeX</span></button></a>
              
            </div>
            

            
            <pre id="bib/turkishcapt.bib" style="display: none;">@inproceedings{samet2017captioning,
  title     = {Could we create a training set for image captioning using automatic translation?},
  author    = {Nermin Samet and Samet Hicsonmez and Pinar Duygulu and Emre Akbas},    
  booktitle = {25th Signal Processing and Communications Applications Conference, {SIU} 2017, Antalya, Turkey, May 15-18, 2017},
  pages     = {1--4},
  year      = {2017},     
  organization={IEEE}
}
</pre>
            
          </td>
        </tr>
        
        
        
        
        
        <tr>
          <td style="padding:2.5%;width:75%;vertical-align:middle">
            <h3>Ground-nesting Insects could use Visual Tracking for Monitoring Nest Position during Learning Flights</h3>
            <br>
            <strong>Nermin Samet</strong>, Jochen Zeil, Elmar Mair, Norbert Boeddeker, Wolfgang Stuerzl

            <br>
            <em>International Conference on Simulation of Adaptive Behavior (SAB)</em> 2014, Best Paper Finalist<br>
            <div class="research-buttons">
              
              
              <a href="https://link.springer.com/chapter/10.1007/978-3-319-08864-8_11" target="_blank"><button type="button" class="research-button"><i class="far fa-file-pdf fa-lg"></i><span>Paper</span></button></a>
              
              
              
              
              
              
              <a href="javascript:toggleBib('bib/insects.bib')"><button type="button" class="research-button"><span>BibTeX</span></button></a>
              
            </div>
            

            
            <pre id="bib/insects.bib" style="display: none;">@inproceedings{samet2014ground,
title={Ground-nesting insects could use visual tracking for monitoring nest position during learning flights},
author={Samet, Nermin and Zeil, Jochen and Mair, Elmar and Boeddeker, Norbert and St{\"u}rzl, Wolfgang},
booktitle={International Conference on Simulation of Adaptive Behavior},
pages={108--120},
year={2014},
organization={Springer International Publishing}
}
</pre>
            
          </td>
        </tr>
        
        
        
      </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody><tr>
          <td style="padding:0px">
            <br>
            <p style="text-align:center;font-size:small;">
              Inspired from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's website</a>
            </p>
          </td>
        </tr>
      </tbody></table>
    </td>
  </tr>
</tbody></table>