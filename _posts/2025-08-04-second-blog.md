---
title: "Breaking LLM Agents"
layout: blog
permalink: /blogs/llm-agents/
author_profile: true
classes: wide
---

<style>
.page__title {
    color: #494e52 !important;
    font-weight: bold;
}

.page__content {
    font-size: 1em;
    color: #494e52;
    line-height: 1.5;
}

.page__content .blog-date {
    font-size: 1em;
    color: #7a8288;
    margin-bottom: 1em;
}

.page__content .blog-section {
    margin-bottom: 1.5em;
}

.page__content .blog-section-title {
    font-size: 1.2em;
    font-weight: bold;
    margin-bottom: 0.8em;
    color: #494e52;
}

.page__content .blog-image {
    text-align: center;
    margin: 1.5em 0;
}

.page__content .read-time {
    font-size: 1em;
    color: #7a8288; 
    margin-top: 1em;
    margin-bottom: 1.5em;
}

.page__content .read-time-icon {
    margin-right: 0.2em;
}

.page__content p {
    font-size: 1.2em !important;
    line-height: 1.6 !important;
}

.page__content ul,
.page__content li {
    font-size: 1em !important;
    line-height: 1.5 !important;
}
</style>

<div class="blog-section">
    <p>As LLM agents spread into products and embodied systems, security and privacy risks grow in both scope and impact. Below is a concise field note on threats, defenses, and representative references for agentic systems across chat and robotics.</p>

    <div class="blog-section-title">Papers published in this domain</div>
    <ul>
        <li>Conseca</li>
        <li>ShieldAgent</li>
        <li>AirGapAgent</li>
        <li>RoboPair</li>
        <li>RoboGuard</li>
        <li>CEE</li>
        <li>J-DAPT</li>
        <li>TocTou</li>
    </ul>
</div>